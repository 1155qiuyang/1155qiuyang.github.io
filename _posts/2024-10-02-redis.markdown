---
layout:       post
title:        "redis常见的问题"
author:       "史密斯"
header-style: text
catalog:      false
tags:
    - C#
    - Bank-end
    - redis
---



Redis 5 种数据结构
String、Hash、List、Set、Zset





Redis5 种数据结构你都使用了哪些，怎么用的
(1)String 用的最多，比如存登录用户的 token，还有项目中一些键 值对的地方

(2)Hash 结构这个也用过，比如文件推送平台，需要区分上游哪个 平台传送过来的文件，
然后文件还要再一次区分是那种类型的文件。 或者针对用户手机唯一 id，
大数据会给一个接口先判断用户是属于哪 种类型的用户，
例如 4 种类型 A,B,C,D，我们平台还需要根据用户所 使用的手机类型做进一步区分，
比如安卓和 ios，然后再给这个用户 推送不同的广告，后台会先配置 A,B,C,D 四种类型的用户，
比如少年， 青年，中年，老年。这个最为 hash 的 key 区分最外层，然后内层的map 再根据手机类型进行区分

(3)Set 结构也用过，比如文件推送过了，我们可以把当天的文件名 保存进一个 set 集合，这样通过 set 的 sismember 命令可以快速判断。
或者把拉黑的用户id存入set集合中，用户进入首页直接判断是否在 set 集合中。
(4)Zset 也用过，比如我们平台会给用户 app 上面推广告，后台会 配置这个广告的运营时间，然后会把这个广告的点击数存在 zset 当做 是分数，
公司后台会根据不同的时间投放点击数不同的广告，这个到 了时间我就会根据 zset 的 zrangebyscore 取的对应的广告进行投放。


这 5 种数据结构底层是什么数据结构有了解吗 (简单描述，不过多写，粉丝难接受) (1)String:底层用的是动态字符串，有动态扩容的能力，
如果字符 串小于 1M 扩容是字符串 2 倍+1,如果大于 1M，则为扩展后的字符串 长度+1M+1,加 1 是结束标识，在字符串长度不一样的时候还会采用不 同的编码格式加快查询效率。

(2)List:redis 最早用的是 ziplist(压缩链表)，但是当元素个数过 多，它的查找效率就会降低。而且如果在 ziplist 里新增或修改数据， ziplist 占用的内存空间还需要重新分配(3.0 版本及之后废弃)。
Redis 先是在 3.0 版本中设计实现了 quicklist。quicklist 结构在 ziplist 基础上，使用链表将 ziplist 串联起来，链表的每个元素就是一个 ziplist。 
这种设计减少了数据插入时内存空间的重新分配，并且 quicklist 限制 了每个节点上 ziplist 的大小，查询效率不会那么低。
Redis 在 5.0 版本中，又实现了 listpack 结构(没有完全替换，不深入 介绍，只要达 quicklist 即可)。

(3)Set :Dict 字典，值为键，value 是 null。

(4)Zset :当元素个数小于128并且每个元素小于64字节采用ziplist 存储，来节省内存。其他情况采用 Dict 字典加跳表的数据结构，DictJI 检查键的唯一性，跳表实现快速排序和查找。

(5)HASH:默认采用ziplist，ziplist相连的两个节点保存key和value。 当数据量大时，ziplist 会有查询效率问题，会转成 Dict 结构存储。



Redis 网络模型了解吗(了解即可，有点难)
我知道有 3 种 select，poll 和 epoll
都使用了 io 多路复用原理。
但是 Select 监听文件(linux 一切东西都是以文件形式表现)有上限， 还涉及不少内核拷贝，并且有事件就绪了需要遍历所有的文件找出就 绪的事件。
Poll 采用链表存储文件解决了 select 监听 select 监听文件上限的问题， 但是有事件发生依然需要遍历整个文件。
Epoll 采用红黑树解决了监听文件上限问题，并且加快了查询就绪事 件的效率，并且添加效率也很快。


Redis setnx 分布式锁有哪些问题
  业务执行时间过长，可能会把其他线程的锁给删了
如何解决:
我使用的 redisson，他有个看门狗机制，会检测程序是否执行完， 没执行完会给锁增加过期时间。

那你说说这个看门狗机制的实现原理
当我们在调用 redission 的 lock 方法时没有指定超时时间，就会 使用看门狗的默认时间 30 秒，只要抢锁成功的线程，
就会开启一个 延迟任务，超过看门狗时间的 1/3 就会重新给这个锁设置过期时间。


Redis 为什么快
(1)Redis 使用了单线程架构+IO 多路复用模型 
(2)纯内存访问
(3)单线程避免了上下文切换带来的资源消耗

什么是缓存击穿、缓存穿透、缓存雪崩
常见的缓存使用方式:读请求来了，先查下缓存，缓存有值命中， 就直接返回，缓存没命中，就去查数据库，然后把数据库的值更新到 缓存，再返回。
1)缓存穿透
指查询一个一定不存在的数据，由于缓存是不命中时需要从数据 库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次 请求都要到数据库去查询，进而给数据库带来压力。

如何避免缓存穿透?
1如果是非法请求，我们在 API 入口，对参数进行校验，过滤非 法值。
2如果查询数据库为空，我们可以给缓存设置个空值，或者默认 值。
3使用布隆过滤器快速判断数据是否存在。即一个查询请求过来
时，先通过布隆过滤器判断值是否存在，存在才继续往下查。


(2)缓存雪崩
指同一个时刻缓存中数据大批量到过期时间失效，而查询数据量 巨大，请求都直接访问数据库，引起数据库压力过大甚至 down 机。 如何避免缓存雪崩?
不要把所有 key 过期时间设置为一样的，让过期时间相对离散一 点。如采用一个较大固定值+一个较小的随机值，5 小时+0 到 1800 秒 这样。
(3)缓存击穿
一个比较热门的键过期了，多个请求访问这个键，因为键不存在 了，这将导致每次访问这个不存在的数据都是直接请求到数据库，增 加数据库压力。

如何避免缓存击穿呢?
1设置热门键不过期 2考虑加分布式锁，获取锁的第一个线程把数据库数据拉出来加进缓 存，后续的请求就不用去数据库查询了

redis 字符串最大不能超过多少
512M


Redis 默认分多少个数据库 16个

Redis 过期策略
(1)定时过期:每个设置过期时间的 key 都需要创建一个定时器， 到过期时间就会立即对 key 进行清除。
(2)惰性过期:只有当访问一个 key 时，才会判断该 key 是否已过 期，过期则清除。 
(3)定期过期:每隔一定的时间，会扫描一定数量的数据库的 expires 字典中一定数量的 key，并清除其中已过期的 key。





Redis 的持久化机制有哪些?优缺点说说 (1)RDB
就是把内存数据以快照的形式保存到磁盘上。RDB 持久化，是指 在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快 照写入磁盘中，它是 Redis 默认的持久化方式。
执行完操作后，在指 定目录下会生成一个 dump.rdb 文件，Redis 重启的时候，通过加载 dump.rdb 文件来恢复数据。
RDB 的优点:适合大规模的数据恢复场景，如备份，全量复制等 RDB 缺点:没办法做到实时持久化/秒级持久化。


(2)AOF
采用日志的形式来记录每个写操作，追加到文件中，重启时再重 新执行 AOF 文件中的命令来恢复数据。它主要解决数据持久化的实 时性问题。默认是不开启的。
AOF 的优点:数据的一致性和完整性更高
AOF 的缺点:AOF 记录的内容越多，文件越大，数据恢复变慢。



MySQL 与 Redis 如何保证双写一致性 
(1)缓存延时双删:先删除缓存，再更新数据库，休眠一会(比如 1 秒)，再次删除缓存。
(2)删除缓存重试机制:写请求更新数据库缓存因为某些原因，删 除失败，把删除失败的 key 放到消息队列，消费消息队列的消息，获 取要删除的 key 重试删除缓存操作 
(3)读取biglog异步删除缓存:以mysql为例，可以使用阿里的canal 将 binlog 日志采集发送到 MQ 队列里面，然后通过 ACK 机制确认处理 这条更新消息，删除缓存，保证数据缓存一致性
Redis 内存溢出策略
1. 当内存使用超过配置的时候会返回错误，不会删除任何键 2. 删除最久没有使用的键
3. 从所有 key 随机删除
4. 从过期键的集合中随机驱逐
5. 从所有键中驱逐使用频率最少的键 Mysql
6. 从设置了过期时间的键集合中驱逐最久没有使用的键
7. 从配置了过期时间的键中驱逐马上就要过期的键
8. 从所有配置了过期时间的键中驱逐使用频率最少的键








mysql 




Mysql 默认的隔离级别
可重复读

说下不可重复读和幻读的区别 不可重复读:在并发更新时，另一个事务前后查询数据不一样
幻读:删除或者新增产生数量变化时，另一事务修改或者删除发现影 响的行数不一样


知道什么是当前读和快照读吗 最普通的查询语句就是当前读，不加锁
加锁是快照度，比如 insert，delete，update，selet* from *** for update


Mysql 是怎么实现可重复读的
(1)快照读:基于 mvcc 多版本并发控制实现的，及 Undo Log +read view 实现的，Undo Log 保存了历史快照，
Read View 可见性规则帮助 判断当前版本的数据是否可见，当事务执行 SQL 语句前，会得到一个Read View，可重复读隔离级别下，一个事务里只会获取一次 read view， 
后面都是共用的，从而保证每次查询的数据都是一样的



(2)当前读:基于行数加间隙锁实现的。

间隙锁了解吗? 间隙锁主要是在索引记录之间的间隙加锁，从而保证某个间隙内的数 据在锁定情况下不会发生任何变化


Mysql 如何排查死锁
可以修改 MySql 系统参数 innodb_print_all_deadlocks 设置成 1，
开启状态，这样当发生死锁时，死锁日志会记录到 MySQL 的错误日 志文件中。
  也可以查看线上的服务器日志




Mysql 有哪几种日志文件
我知道的主要有 6 种日志,重做日志(redo log)、回滚日志(undo
log)、二进制日志(binlog)、错误日志(errorlog)、慢查询日志(slow query log)、一般查询日志(general log)




都有什么作用
(1)binlog 是 MySQ 服务层维护的一种二进制日志，主要做主 从复制、数据恢复和备份;
(2)undo log innerdb 储存引擎层面的日志，提供回滚和多版本 并发控制下的读(MVCC);
(3)redo log 数据备份和数据提交;
(4)errorlog mysql 服务器执行错误时记录进这个错误日志;
(5)slow query log mysql 开启了慢查询，慢 sql 会写入这里;
(6)general log 记录所有的操作日志一般不开启，耗费数据库 性能。



redo log 与 binlog 的区别
(1)redo log 是在 InnoDB 存储引擎层产生，而 binlog 是 MySQL
数据库的上层产生的
(2)写入磁盘的时间点不同，binlog 在事务提交完成后进行一
次写入。而 redo log 在事务进行中不断地被写入
(3)binlog 在写满或者重启之后，会生成新的 binlog 文件，redo
log 是循环使用



Mysql 锁你了解几种(都有什么作用)
主要了解4种
(1)行锁 锁定一行，锁的是索引，解决当多个线程对数据库进 行操作时，会带来数据不一致的情况，会有死锁情况;
(2)表锁 锁定整张表，也是防止解决当多个线程对数据库进行 操作时，会带来数据不一致的情况，不会有死锁;
(3)间隙锁 只有在可重复读的情况下才会有可能产生此锁，可 以避免幻读，锁的是索引的一段间隔，会有死锁情况;
(4)意向锁，是一种表级锁，与行锁可以同时存在，目的是防 止加表锁时需要全表扫描有没有行锁，不会有死锁情况。



什么是索引下推
在 mysql5.6 之前，没有索引下推，比如建立了一个联合索引，先会从第一个索引里面找到合适的数据，再回表查，再过滤，造成多次 回表。
而 5.6 之后有引入索引下推，主要直接就可以根据两个联合索引 过滤出需要的数据，再回表，减少了回表查的次数。



CHAR 和 VARCHAR 区别?
(1)char 表示定长，长度固定，varchar 表示变长，长度可变，char 如果插入的长度小于定义长度时，用空格填充，varchar 小于定义长 度时，还是按实际长度存储。
(2)存储的容量不同，对 char 来说，最多能存放字符个数 255，和 编码无关，对 varchar 来说，最多存放 65532 个字符。


索引是什么
一种有序的能够实现快速查找的数据结构。


索引的分类 从物理结构上可以分为聚集索引和非聚集索引两类。 从应用上可以划分为一下几类:普通索引、唯一索引(可以有 null)、 主键索引(不可以有 null)、联合索引。
从数据结构上分有 Hash、BTree、B+Tree 等。

索引设计原则?
(1)选择唯一性索引; 
(2)为经常作为查询条件的字段建立索引;
(3)为经常需要排序、分组和联合操作的字段建立索引; 
(4)限制索引的数目;
(5)小表不建议索引(如数量级在百万以内);
(6)尽量使用数据量少的索引; 
(7)删除不再使用或者很少使用的索引; 
(8)字段中重复值比较多的不适合建索引，比如性别;
(9)尽量使用前缀来索引，利用最左前缀。

创建索引语句
creat index idx_user_nameEmail on user(name,email);


为何使用 B+树而非 B 树做索引?
(1)B+ 树减少了 IO 次数;
(2)B+ 树查询效率更稳定(查找效率固定为 O(log n));

(3)B+ 树更加适合范围查找(B+树叶子结点之间用链表有序连接)。


MyISAM 和 InnoDB 的区别?
(1)InnoDB 支持事务，MyISAM 不支持 ;
(2)InnoDB 支持外键，而 MyISAM 不支持;
(3)InnoDB 和 MyISAM 均支持 B+ Tree 数据结构的索引。但 InnoDB 是聚集索引，而 MyISAM 是非聚集索引;
(4)InnoDB 不保存表中数据行数，执行 select count(*) from table 时 需要全表扫描。而 MyISAM 用一个变量记录了整个表的行数，速度相 当快(注意不能有 WHERE 子句);
(5)InnoDB 支持表、行(默认)级锁，而 MyISAM 支持表级锁。



什么是数据库的事务?
数据库的事务是一个不可分割的数据库操作序列，事务是逻辑上 的一组操作，要么都执行，要么都不执行。



什么是事务的四大特性(ACID)? 
(1)原子性:事务是最小的执行单位，不允许分割。事务的原子性 确保动作要么全部完成，要么完全不起作用 
(2)一致性:事务执行前后，数据保持一致，多个事务对同一个数 据读取的结果是相同的 
(3)隔离性:并发访问数据库时，一个用户的事务不被其他事务所 干扰，各并发事务之间数据库是独立的 
(4)持久性:一个事务被提交之后。它对数据库中数据的改变是持 久的，即使数据库发生故障也不应该对其有任何影响。



什么是脏读、幻读和不可重复读? (1)脏读:一个事务读取到另一个事务尚未提交的数据。事务 A 读 取事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏 数据。 
(2)不可重复读:一个事务中两次读取的数据的内容不一致。 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作 了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。
(3)幻读:一个事务中两次读取的数据量不一致。
系统管理员 A 将 数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管 理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这 就叫幻读。

like 走索引吗?
xxx%走索引，%xxx 不走索引

如果我就想用 like，如何保证不失效?
使用覆盖索引。



什么是覆盖索引?
如果一个索引包含(覆盖)所有需要查询的字段的值，称为覆盖索引。



索引不生效的情况
(1)不满足最左匹配原则
(2)使用不等于查询
(3)在索引列上使用了函数
(4)使用范围条件，范围之后全失效 
(5)使用 like 时左边是通配符 
(6)使用 is null 和 is not null 
(7)字符串不加单引号
(8)用 or 也可能导致索引失效





你知道哪些加密算法
(1)我知道有 MD5 算法，MD5 算法主要用的是 哈希函数，不可逆， 无论传入多长的字符串，MD5 都会输出长度为 128bits 的一个串。 
(2)还有 DES 加密算法，他的话是主要是 64 位为分组对数据加密， 它的密钥长度 是 56 位，加密解密用同一算法。
(3)对 RSA 也了解一点，这种加密算法是将两个大素数相乘很容易， 但想要对这个乘积进行因式分解就比较困难了，所以一般将乘积作为 加密密钥。





1.说一个栈溢出的例子
方法无限递归
2.说几个堆溢出的例子 循环创建对象，或者一次性从数据库查出很多数据 3.说一个元空间溢出的例子
循环利用反射创建对象


4.你知道什么是跨域问题吗? 浏览器为了让自己更安全，设置了一种同源策略，"协议+域名+端口" 三者都相同才算同源，不然会阻止一些请求。

5.如何解决跨域问题?
(1)创建一个过滤器，然后把一些来源，请求头和请求方法等都设置成全部允许
(2)可以在类或者方法上面加@CrossOrigin 注解
(3)还可以在 nginx 配置文件配置允许跨域







elasticsearch

1. 说说你们公司 es 的集群架构，索引数据大小，分片有多少，以及一些调优手段 。
节点数、分片数、副本数，尽量根据自己公司使用情况回答，当然适当放大也可行。

调优手段是现在很常见的面试题，下面这几种调优手段一定要了解懂。当然，下面的每一条都可以当做调优的一部分。

设计调优

a. 根据业务增量需求，采取基于日期模板创建索引，通过 rollover API 滚动索引；
b. 使用别名进行索引管理；（es的索引名不能改变，提供的别名机制使用非常广泛。）
c. 每天凌晨定时对索引做force_merge操作，以释放空间；
d. 采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储；
e. 采取curator进行索引的生命周期管理；
f. 仅针对需要分词的字段，合理的设置分词器；
g. Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。




写入调优

写入前副本数设置为0；
写入前关闭refresh_interval设置为-1，禁用刷新机制；
写入过程中：采取bulk批量写入；
写入后恢复副本数和刷新间隔；
尽量使用自动生成的id。



查询调优

禁用wildcard；（通配符模式，类似于%like%）
禁用批量terms（成百上千的场景）；
充分利用倒排索引机制，能keyword类型尽量keyword；
数据量大时候，可以先基于时间敲定索引再检索；
设置合理的路由机制。



elasticsearch 的倒排索引是什么
倒排索引也就是单词到文档的映射，当然不只是存里文档id这么简单。还包括：词频（TF，Term Frequency）、偏移量（offset）、位置（Posting）。





elasticsearch 是如何实现 master 选举的
ElasticSearch 的选主是 ZenDiscovery 模块负责
对所有可以成为 Master 的节点（node.master: true）根据 nodeId 排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是 Master 节点。
如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举。
(当然也可以自己设定一个值，最小值设定为超过能成为Master节点的n/2+1，否则会出现脑裂问题。discovery.zen.minimum_master_nodes)



描述一下 Elasticsearch 索引文档的过程

客户端向 Node 1 发送新建、索引或者删除请求。
节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。
Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。



当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 MemoryBuffer，然后定时（默认是每隔 1 秒）写入到 Filesystem Cache，
这个从 MomeryBuffer 到 Filesystem Cache 的过程就叫做 refresh；
当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失，ES 是通过 translog 的机制来保证数据的可靠性的。
其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；
在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。
flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）时；



1. translog 可以理解为就是一个文件，一直追加。
2. MemoryBuffer 应用缓存。
3. Filesystem Cache 系统缓冲区。



延伸阅读：Lucene 的 Segement:

Lucene 索引是由多个段组成，段本身是一个功能齐全的倒排索引。
段是不可变的，允许 Lucene 将新的文档增量地添加到索引中，而不用从头重建索引。
对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗CPU 的时钟周、文件句柄和内存。这意味着段的数量越多，搜索性能会越低。
为了解决这个问题，Elasticsearch 会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。




详细描述一下 Elasticsearch 搜索的过程？
es作为一个分布式的存储和检索系统，每个文档根据 _id 字段做路由分发被转发到对应的shard上。
搜索执行阶段过程分俩个部分，我们称之为 Query Then Fetch。





query-查询阶段

当一个search请求发出的时候，这个query会被广播到索引里面的每一个shard（主shard或副本shard），每个shard会在本地执行查询请求后会生成一个命中文档的优先级队列。

这个队列是一个排序好的top N数据的列表，它的size等于from+size的和，也就是说如果你的from是10，size是10，那么这个队列的size就是20，
所以这也是为什么深度分页不能用from+size这种方式，因为from越大，性能就越低。



查询阶段包含以下三个步骤:

客户端发送一个 search 请求到 Node 3 ， Node 3 会创建一个大小为 from + size 的空优先队列。
Node 3 将查询请求转发到索引的每个主分片或副本分片中。每个分片在本地执行查询并添加结果到大小为 from + size 的本地有序优先队列中。
每个分片返回各自优先队列中所有文档的 ID 和排序值给协调节点，也就是 Node 3 ，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。



fetch - 读取阶段 / 取回阶段


分布式阶段由以下步骤构成：

协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。
每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。
一旦所有的文档都被取回了，协调节点返回结果给客户端。
协调节点首先决定哪些文档 确实 需要被取回。例如，如果我们的查询指定了 { "from": 90, "size": 10 } ，最初的90个结果会被丢弃，只有从第91个开始的10个结果需要被取回。
这些文档可能来自和最初搜索请求有关的一个、多个甚至全部分片。

协调节点给持有相关文档的每个分片创建一个 multi-get request ，并发送请求给同样处理查询阶段的分片副本。

分片加载文档体-- _source 字段—​如果有需要，用元数据和 search snippet highlighting 丰富结果文档。 一旦协调节点接收到所有的结果文档，它就组装这些结果为单个响应返回给客户端。







拓展阅读：
深翻页（Deep Pagination）
先查后取的过程支持用 from 和 size 参数分页，但是这是 有限制的 。
要记住需要传递信息给协调节点的每个分片必须先创建一个 from + size 长度的队列，协调节点需要根据 number_of_shards * (from + size) 排序文档，来找到被包含在 size 里的文档。

取决于你的文档的大小，分片的数量和你使用的硬件，给 10,000 到 50,000 的结果文档深分页（ 1,000 到 5,000 页）是完全可行的。但是使用足够大的 from 值，排序过程可能会变得非常沉重，使用大量的CPU、内存和带宽。因为这个原因，我们强烈建议你不要使用深分页。

实际上， “深分页” 很少符合人的行为。当2到3页过去以后，人会停止翻页，并且改变搜索标准。会不知疲倦地一页一页的获取网页直到你的服务崩溃的罪魁祸首一般是机器人或者web spider。

如果你 确实 需要从你的集群取回大量的文档，你可以通过用 scroll 查询禁用排序使这个取回行为更有效率，我们会在 later in this chapter 进行讨论。
注：https://www.elastic.co/guide/cn/elasticsearch/guide/current/scroll.html



Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法
关闭缓存swap;
原因：大多数操作系统会将内存使用到文件系统缓存，会将应用程序未用到的内存交换出去。会导致jvm的堆内存交换到磁盘上。交换会导致性能问题。会导致内存垃圾回收延长。会导致集群节点响应时间变慢，或者从集群中断开。
堆内存设置为：Min（节点内存/2, 32GB）;
设置最大文件句柄数；




Elasticsearch 中的节点（比如共 20 个），其中的 10 个选了一个 master，另外 10 个选了另一个 master，怎么办？
当集群 master 候选数量不小于 3 个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；
当候选数量为两个时，只能修改为唯一的一个 master 候选，其他作为 data节点，避免脑裂问题。



客户端在和集群连接时，如何选择特定的节点执行请求的？
client 远程连接连接一个 elasticsearch 集群。它并不加入到集群中，只是获得一个或者多个初始化的地址，并以轮询的方式与这些地址进行通信。


详细描述一下 Elasticsearch 更新和删除文档的过程。
删除和更新也都是写操作，但是 Elasticsearch 中的文档是不可变的，因此不能被删除或者改动以展示其变更；(根本原因是底层lucene的segment段文件不可更新删除)
磁盘上的每个段都有一个相应的 .del 文件。当删除请求发送后，文档并没有真 的被删除，而是在 .del 文件中被标记为删除。该文档依然能匹配查询，但是会在 结果中被过滤掉。当段合并时，在.del 文件中被标记为删除的文档将不会被写入 新段。
在新的文档被创建时，Elasticsearch 会为该文档指定一个版本号，当执行更新 时，旧版本的文档在.del 文件中被标记为删除，新版本的文档被索引到一个新段。




Elasticsearch 对于大数据量（上亿量级）的聚合如何实现？
这道题目较难，相信大家看到很多类似这种回答
Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。
HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。






科普&拓展：

HyperLogLog：
下面简称为HLL，它是 LogLog 算法的升级版，作用是能够提供不精确的去重计数。存在以下的特点：
1. 能够使用极少的内存来统计巨量的数据，在 Redis 中实现的 HyperLogLog，只需要12K内存就能统计2^64个数据。
2. 计数存在一定的误差，误差率整体较低。标准误差为 0.81% 。
3. 误差可以被设置辅助计算因子进行降低。
---
应用场景：
1. 基数不大，数据量不大就用不上，会有点大材小用浪费空间
2. 有局限性，就是只能统计基数数量，而没办法去知道具体的内容是什么
3. 和bitmap相比，属于两种特定统计情况，简单来说，HyperLogLog 去重比 bitmap 方便很多
4. 一般可以bitmap和hyperloglog配合使用，bitmap标识哪些用户活跃，hyperloglog计数
---
应用场景：
1. 基数不大，数据量不大就用不上，会有点大材小用浪费空间
2. 有局限性，就是只能统计基数数量，而没办法去知道具体的内容是什么
3. 和bitmap相比，属于两种特定统计情况，简单来说，HyperLogLog 去重比 bitmap 方便很多
4. 一般可以bitmap和hyperloglog配合使用，bitmap标识哪些用户活跃，hyperloglog计数






在并发情况下，Elasticsearch 如果保证读写一致？
首先要了解什么是一致性，在分布式系统中，我们一般通过CPA理论分析。
分布式系统不可能同时满足一致性（C：Consistency）、可用性（A：Availability）和分区容忍性（P：Partition Tolerance），最多只能同时满足其中两项。


可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。









